{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# run_analysis.py\n",
        "# Standalone Python script to run the DeepMethyGene analysis from the command line.\n",
        "\n",
        "import os\n",
        "import json\n",
        "import ast\n",
        "import argparse\n",
        "from typing import List, Dict, Tuple, Optional\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# ==============================================================================\n",
        "# UTILITY AND MODEL DEFINITIONS\n",
        "# (Copied directly from iGEM-9.1-SLC7A5.ipynb for a self-contained script)\n",
        "# ==============================================================================\n",
        "\n",
        "def _standardize_chr(x: str) -> str:\n",
        "    \"\"\"Ensures chromosome names start with 'chr'.\"\"\"\n",
        "    x = str(x).strip()\n",
        "    return x if x.startswith(\"chr\") else f\"chr{x}\"\n",
        "\n",
        "def load_promoters_hg19(promoter_file: str) -> pd.DataFrame:\n",
        "    \"\"\"Loads and preprocesses the hg19 promoter file.\"\"\"\n",
        "    prom = pd.read_csv(promoter_file, sep=\"\\t\", dtype={\"chrID\": str})\n",
        "    prom = prom.rename(columns={\"gene name\": \"gene\", \"chrID\": \"seqnames\"})\n",
        "    prom[\"gene\"] = prom[\"gene\"].astype(str).str.upper().str.strip()\n",
        "    prom[\"seqnames\"] = prom[\"seqnames\"].astype(str).map(_standardize_chr)\n",
        "    prom[\"start\"] = pd.to_numeric(prom[\"start\"], errors=\"coerce\").astype(\"Int64\")\n",
        "    prom = prom.dropna(subset=[\"start\"]).astype({\"start\": \"int64\"}).drop_duplicates()\n",
        "    return prom[[\"gene\", \"seqnames\", \"start\"]]\n",
        "\n",
        "def resolve_input_probes(\n",
        "    gene: str,\n",
        "    long_df: pd.DataFrame,\n",
        "    mapped_csv: Optional[str] = \"mapped_filteredgenes_data.csv\",\n",
        ") -> List[str]:\n",
        "    \"\"\"Resolves the exact probe order for the model input vector.\"\"\"\n",
        "    gene_u = gene.upper()\n",
        "    if mapped_csv and os.path.exists(mapped_csv):\n",
        "        try:\n",
        "            m = pd.read_csv(mapped_csv)\n",
        "            mg = m[m[\"gene\"].astype(str).str.upper() == gene_u]\n",
        "            if not mg.empty and \"cpg_probe_ids\" in mg.columns:\n",
        "                raw = mg.iloc[0][\"cpg_probe_ids\"]\n",
        "                out = ast.literal_eval(str(raw))\n",
        "                out = [str(v) for v in out if str(v) != \"nan\"]\n",
        "                if out:\n",
        "                    print(f\"[Info] Resolved probe order from '{mapped_csv}' (n={len(out)})\")\n",
        "                    return out\n",
        "        except Exception as e:\n",
        "            print(f\"[Warning] Could not parse mapped CSV: {e}\")\n",
        "\n",
        "    sub = long_df[long_df[\"gene\"].astype(str).str.upper() == gene_u].copy()\n",
        "    if sub.empty:\n",
        "        raise ValueError(f\"Could not resolve input probes for {gene_u}\")\n",
        "    if {\"chr\", \"start\", \"probe_id\"}.issubset(sub.columns):\n",
        "        sub = sub.drop_duplicates(\"probe_id\").sort_values([\"chr\", \"start\"])\n",
        "        out = sub[\"probe_id\"].astype(str).tolist()\n",
        "        print(f\"[Info] Resolved probe order from long_df by genomic sort (n={len(out)})\")\n",
        "        return out\n",
        "    return sub.drop_duplicates(\"probe_id\")[\"probe_id\"].astype(str).tolist()\n",
        "\n",
        "def pick_sample(df_long: pd.DataFrame, gene: str, sample: Optional[str]) -> str:\n",
        "    \"\"\"Picks a sample for analysis, defaulting to the first available one.\"\"\"\n",
        "    df_g = df_long[df_long[\"gene\"].str.upper() == gene.upper()]\n",
        "    if df_g.empty: raise ValueError(f\"No rows for gene {gene} in long data.\")\n",
        "    samples = sorted(df_g[\"sample\"].astype(str).unique())\n",
        "    if not samples: raise ValueError(f\"No samples available for gene {gene}.\")\n",
        "    if sample is None: return samples[0]\n",
        "    sample = str(sample)\n",
        "    if sample not in samples: raise ValueError(f\"Sample {sample} not found for {gene}.\")\n",
        "    return sample\n",
        "\n",
        "def promoter_mask(\n",
        "    input_probes: List[str], sub_long: pd.DataFrame, promoters: pd.DataFrame,\n",
        "    gene: str, window_bp: int\n",
        ") -> np.ndarray:\n",
        "    \"\"\"Creates a boolean mask for probes within a promoter window.\"\"\"\n",
        "    gene_u = gene.upper()\n",
        "    pos = sub_long.drop_duplicates(\"probe_id\").set_index(\"probe_id\")[[\"chr\", \"start\"]].to_dict(\"index\")\n",
        "    gp = promoters[promoters[\"gene\"] == gene_u]\n",
        "    if gp.empty: return np.zeros(len(input_probes), dtype=bool)\n",
        "\n",
        "    gp_by_chr: Dict[str, List[int]] = {}\n",
        "    for _, r in gp.iterrows(): gp_by_chr.setdefault(str(r[\"seqnames\"]), []).append(int(r[\"start\"]))\n",
        "\n",
        "    mask = np.zeros(len(input_probes), dtype=bool)\n",
        "    for i, pid in enumerate(input_probes):\n",
        "        info = pos.get(pid)\n",
        "        if info is None: continue\n",
        "        c, s = str(info[\"chr\"]), int(info[\"start\"])\n",
        "        for tss in gp_by_chr.get(c, []):\n",
        "            if (s >= tss - window_bp) and (s <= tss + window_bp):\n",
        "                mask[i] = True\n",
        "                break\n",
        "    return mask\n",
        "\n",
        "# --- PyTorch Model Definition ---\n",
        "class ResidualBlock(nn.Module):\n",
        "    def __init__(self, channels):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv1d(channels, channels, kernel_size=3, padding=1)\n",
        "        self.conv2 = nn.Conv1d(channels, channels, kernel_size=3, padding=1)\n",
        "        self.act = nn.LeakyReLU(0.01)\n",
        "    def forward(self, x):\n",
        "        res = x; x = self.act(self.conv1(x)); x = self.conv2(x); x = x + res; return self.act(x)\n",
        "\n",
        "class AdaptiveRegressionCNN(nn.Module):\n",
        "    def __init__(self, input_size):\n",
        "        super().__init__()\n",
        "        out1 = min(64, max(1, input_size // 10))\n",
        "        out2 = min(32, max(1, input_size // 20))\n",
        "        self.conv1 = nn.Conv1d(1, out1, kernel_size=3, padding=1)\n",
        "        self.res1 = ResidualBlock(out1)\n",
        "        self.conv2 = nn.Conv1d(out1, out2, kernel_size=3, padding=1)\n",
        "        self.res2 = ResidualBlock(out2)\n",
        "        self.act = nn.LeakyReLU(0.01)\n",
        "        with torch.no_grad():\n",
        "            h = self.res2(self.act(self.conv2(self.res1(self.act(self.conv1(torch.randn(1, 1, input_size)))))))\n",
        "            self._to_linear = h.view(1, -1).shape[1]\n",
        "        self.fc1 = nn.Linear(self._to_linear, 512)\n",
        "        self.fc2 = nn.Linear(512, 1)\n",
        "    def forward(self, x):\n",
        "        x = self.act(self.conv1(x)); x = self.res1(x); x = self.act(self.conv2(x)); x = self.res2(x)\n",
        "        x = x.view(x.size(0), -1); x = self.act(self.fc1(x)); return self.fc2(x).squeeze(-1)\n",
        "\n",
        "def load_gene_model_cnn_only(gene: str, models_dir: str, device: str = \"cpu\"):\n",
        "    \"\"\"Loads the pre-trained CNN model for a specific gene.\"\"\"\n",
        "    gene_u = gene.upper()\n",
        "    meta_path = os.path.join(models_dir, f\"{gene_u}.json\")\n",
        "    if not os.path.exists(meta_path): raise FileNotFoundError(f\"Metadata for {gene_u} not found\")\n",
        "    with open(meta_path, \"r\") as f: meta = json.load(f)\n",
        "    if \"input_size\" not in meta: raise ValueError(f\"meta missing 'input_size'\")\n",
        "\n",
        "    input_size = int(meta[\"input_size\"])\n",
        "    model_path = os.path.join(models_dir, f\"{gene_u}.pt\")\n",
        "    if not os.path.exists(model_path): raise FileNotFoundError(f\"Weights for {gene_u} not found\")\n",
        "\n",
        "    model = AdaptiveRegressionCNN(input_size=input_size)\n",
        "    state_dict = torch.load(model_path, map_location=device)\n",
        "    model.load_state_dict(state_dict); model.to(device).eval()\n",
        "    print(f\"[Info] Loaded model '{gene_u}.pt' with input size {input_size}\")\n",
        "    return model, input_size\n",
        "\n",
        "def vector_from_long(\n",
        "    df_long: pd.DataFrame, gene: str, sample: str, input_probes: List[str], fill_missing: float = 0.0\n",
        ") -> Tuple[np.ndarray, pd.DataFrame]:\n",
        "    \"\"\"Builds the input vector for a given gene and sample.\"\"\"\n",
        "    gene_u = gene.upper()\n",
        "    sub = df_long[(df_long[\"gene\"].str.upper() == gene_u) & (df_long[\"sample\"] == sample)]\n",
        "    if sub.empty: raise ValueError(f\"No rows for {gene_u} / sample {sample}\")\n",
        "    sub = sub.drop_duplicates(\"probe_id\").copy()\n",
        "    m_by_probe = dict(zip(sub[\"probe_id\"].astype(str), sub[\"m_value\"]))\n",
        "    x = np.array([m_by_probe.get(pid, fill_missing) for pid in input_probes], dtype=np.float32)\n",
        "    return x, sub\n",
        "\n",
        "def _predict_tensor(model: nn.Module, x_arr_1d: np.ndarray, device: str = \"cpu\") -> float:\n",
        "    \"\"\"Performs a prediction on a single 1D numpy array.\"\"\"\n",
        "    x = torch.from_numpy(x_arr_1d).float().unsqueeze(0).unsqueeze(1).to(device)\n",
        "    with torch.no_grad(): y = model(x).cpu().numpy().reshape(-1)[0]\n",
        "    return float(y)\n",
        "\n",
        "# ==============================================================================\n",
        "# MAIN ANALYSIS FUNCTION\n",
        "# ==============================================================================\n",
        "\n",
        "def perform_analysis(args):\n",
        "    \"\"\"Main function to orchestrate the data loading, analysis, and plotting.\"\"\"\n",
        "    # --- Setup ---\n",
        "    target_gene = args.gene.upper()\n",
        "    device = \"cuda\" if torch.cuda.is_available() and not args.cpu else \"cpu\"\n",
        "    print(f\"Using device: {device}\")\n",
        "    os.makedirs(args.output_dir, exist_ok=True)\n",
        "\n",
        "    # --- Load data ---\n",
        "    print(\"Loading and preprocessing data files...\")\n",
        "    df_long = pd.read_csv(args.long_csv)\n",
        "    df_long[\"gene\"] = df_long[\"gene\"].astype(str).str.upper().str.strip()\n",
        "    df_long[\"sample\"] = df_long[\"sample\"].astype(str)\n",
        "    df_long[\"chr\"] = df_long[\"chr\"].astype(str).map(_standardize_chr)\n",
        "    df_long[\"start\"] = pd.to_numeric(df_long[\"start\"], errors=\"coerce\").astype(\"Int64\")\n",
        "    df_long = df_long.dropna(subset=[\"start\"]).astype({\"start\": \"int64\"})\n",
        "\n",
        "    promoters = load_promoters_hg19(args.promoter_file)\n",
        "\n",
        "    # --- Resolve inputs for the target gene ---\n",
        "    input_probes = resolve_input_probes(target_gene, df_long, args.mapped_csv)\n",
        "    sample_id = pick_sample(df_long, target_gene, sample=None)\n",
        "    print(f\"Using auto-selected sample: {sample_id}\")\n",
        "\n",
        "    x_base, sub = vector_from_long(df_long, target_gene, sample_id, input_probes, fill_missing=0.0)\n",
        "\n",
        "    # --- Load Model ---\n",
        "    model, input_size = load_gene_model_cnn_only(target_gene, models_dir=args.weights_dir, device=device)\n",
        "\n",
        "    # Align vector length to model's expected input size\n",
        "    if len(input_probes) != input_size:\n",
        "        print(f\"[Warning] Probe list length ({len(input_probes)}) differs from model input size ({input_size}). Will truncate/pad.\")\n",
        "        if len(input_probes) > input_size:\n",
        "            x_base = x_base[:input_size]\n",
        "            input_probes = input_probes[:input_size]\n",
        "        else:\n",
        "            pad_n = input_size - len(input_probes)\n",
        "            x_base = np.concatenate([x_base, np.full(pad_n, 0.0, dtype=np.float32)])\n",
        "            input_probes += [\"__PAD__\"] * pad_n\n",
        "\n",
        "    # --- Task 1: 4-scenario bar plot ---\n",
        "    print(\"\\n--- Running Task 1: 4-Scenario Prediction ---\")\n",
        "    pmask_task1 = promoter_mask(input_probes, sub, promoters, target_gene, window_bp=2000)\n",
        "    preds = {}\n",
        "    preds[\"Baseline\"] = _predict_tensor(model, x_base.copy(), device)\n",
        "    x_hyper, x_hypo = x_base.copy(), x_base.copy()\n",
        "    x_hyper[pmask_task1], x_hypo[pmask_task1] = 10.0, -10.0\n",
        "    preds[\"Promoter\\nHypermethylated\"] = _predict_tensor(model, x_hyper, device)\n",
        "    preds[\"Promoter\\nHypomethylated\"] = _predict_tensor(model, x_hypo, device)\n",
        "\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.bar(preds.keys(), preds.values(), color=['#3b82f6', '#ef4444', '#22c55e'])\n",
        "    plt.ylabel(\"Predicted Expression\")\n",
        "    plt.title(f\"Task 1: {target_gene} Expression Changes (Sample: {sample_id})\")\n",
        "    plt.xticks(rotation=15)\n",
        "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "\n",
        "    task1_plot_path = os.path.join(args.output_dir, f\"{target_gene}_task1_scenarios.png\")\n",
        "    plt.savefig(task1_plot_path, bbox_inches='tight')\n",
        "    plt.close()\n",
        "    print(f\"Saved plot: {task1_plot_path}\")\n",
        "\n",
        "    # --- Task 2: Sweep window hypomethylation ---\n",
        "    print(\"\\n--- Running Task 2: Hypomethylation Window Sweep ---\")\n",
        "    rows = []\n",
        "    for W in range(1000, 10001, 1000):\n",
        "        pmask = promoter_mask(input_probes, sub, promoters, target_gene, window_bp=W)\n",
        "        x_edit = x_base.copy(); x_edit[pmask] = -10.0\n",
        "        rows.append({\"window_bp\": W, \"y_pred\": _predict_tensor(model, x_edit, device)})\n",
        "    df2 = pd.DataFrame(rows)\n",
        "\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.plot(df2[\"window_bp\"], df2[\"y_pred\"], marker=\"o\")\n",
        "    plt.xlabel(\"Promoter Window Size (±bp)\")\n",
        "    plt.ylabel(\"Predicted Expression\")\n",
        "    plt.title(f\"Task 2: {target_gene} Expression vs. Hypo-methylated Window\")\n",
        "    plt.grid(True, linestyle=':')\n",
        "\n",
        "    task2_plot_path = os.path.join(args.output_dir, f\"{target_gene}_task2_window_sweep.png\")\n",
        "    plt.savefig(task2_plot_path, bbox_inches='tight')\n",
        "    plt.close()\n",
        "    print(f\"Saved plot: {task2_plot_path}\")\n",
        "\n",
        "    task2_csv_path = os.path.join(args.output_dir, f\"{target_gene}_task2_window_sweep.csv\")\n",
        "    df2.to_csv(task2_csv_path, index=False)\n",
        "    print(f\"Saved data: {task2_csv_path}\")\n",
        "\n",
        "    # --- Task 3: Sweep promoter methylation level ---\n",
        "    print(\"\\n--- Running Task 3: Promoter Methylation Level Sweep ---\")\n",
        "    pmask3 = promoter_mask(input_probes, sub, promoters, target_gene, window_bp=2000)\n",
        "    levels, preds3 = [], []\n",
        "    for level in np.arange(10.0, -10.5, -0.5):\n",
        "        x_edit = x_base.copy()\n",
        "        x_edit[pmask3] = level\n",
        "        levels.append(level)\n",
        "        preds3.append(_predict_tensor(model, x_edit, device))\n",
        "    df3 = pd.DataFrame({\"promoter_level\": levels, \"y_pred\": preds3})\n",
        "\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.plot(df3[\"promoter_level\"], df3[\"y_pred\"], marker=\"o\")\n",
        "    plt.xlabel(\"Promoter CpG M-value (within ±2000bp)\")\n",
        "    plt.ylabel(\"Predicted Expression\")\n",
        "    plt.title(f\"Task 3: {target_gene} Expression vs. Promoter Methylation Level\")\n",
        "    plt.grid(True, linestyle=':')\n",
        "    plt.gca().invert_xaxis() # Show hypermethylation on the left\n",
        "\n",
        "    task3_plot_path = os.path.join(args.output_dir, f\"{target_gene}_task3_level_sweep.png\")\n",
        "    plt.savefig(task3_plot_path, bbox_inches='tight')\n",
        "    plt.close()\n",
        "    print(f\"Saved plot: {task3_plot_path}\")\n",
        "\n",
        "    task3_csv_path = os.path.join(args.output_dir, f\"{target_gene}_task3_level_sweep.csv\")\n",
        "    df3.to_csv(task3_csv_path, index=False)\n",
        "    print(f\"Saved data: {task3_csv_path}\")\n",
        "\n",
        "    print(f\"\\nAnalysis for {target_gene} complete. Outputs are in '{args.output_dir}'.\")\n",
        "\n",
        "\n",
        "# ==============================================================================\n",
        "# COMMAND LINE INTERFACE\n",
        "# ==============================================================================\n",
        "if __name__ == \"__main__\":\n",
        "    parser = argparse.ArgumentParser(\n",
        "        description=\"Run DeepMethyGene analysis for a specific gene.\",\n",
        "        formatter_class=argparse.ArgumentDefaultsHelpFormatter\n",
        "    )\n",
        "\n",
        "    # --- Required Arguments ---\n",
        "    parser.add_argument(\n",
        "        \"--gene\",\n",
        "        type=str,\n",
        "        required=True,\n",
        "        help=\"The target gene symbol to analyze (e.g., SLC7A5).\"\n",
        "    )\n",
        "\n",
        "    # --- File Path Arguments ---\n",
        "    parser.add_argument(\n",
        "        \"--long-csv\",\n",
        "        type=str,\n",
        "        default=\"data/m_arrays_for_edit.csv\",\n",
        "        help=\"Path to the long-format methylation data CSV.\"\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"--mapped-csv\",\n",
        "        type=str,\n",
        "        default=\"data/mapped_filteredgenes_data.csv\",\n",
        "        help=\"Path to the mapped genes data with probe order.\"\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"--promoter-file\",\n",
        "        type=str,\n",
        "        default=\"data/hg19_promoter.txt\",\n",
        "        help=\"Path to the hg19 promoter annotation file.\"\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"--weights-dir\",\n",
        "        type=str,\n",
        "        default=\"Gene Wise Model Weights\",\n",
        "        help=\"Directory containing the pre-trained model weights (.pt and .json files).\"\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"--output-dir\",\n",
        "        type=str,\n",
        "        default=\"predictions_out\",\n",
        "        help=\"Directory where output plots and CSVs will be saved.\"\n",
        "    )\n",
        "\n",
        "    # --- Computation Arguments ---\n",
        "    parser.add_argument(\n",
        "        \"--cpu\",\n",
        "        action=\"store_true\",\n",
        "        help=\"Force the use of CPU even if a GPU is available.\"\n",
        "    )\n",
        "\n",
        "    args = parser.parse_args()\n",
        "\n",
        "    try:\n",
        "        perform_analysis(args)\n",
        "    except (FileNotFoundError, ValueError) as e:\n",
        "        print(f\"\\nERROR: {e}\")\n",
        "        print(\"Please check your file paths and ensure the gene exists in the data.\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "akY_Aj3maLSk"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}